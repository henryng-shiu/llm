{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO36R/eCL3lk2svWAbeH/1/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/henryng-shiu/llm/blob/main/LangChain_Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "iRTe2KvRDBFP"
      },
      "outputs": [],
      "source": [
        "!pip -q install openai langchain huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = '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'\n",
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] = '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'"
      ],
      "metadata": {
        "id": "0aQ8t8f8ExQW"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "70GH_lFsMBwM"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import HuggingFaceHub\n",
        "\n",
        "llm_hf = HuggingFaceHub(\n",
        "    repo_id='google/flan-t5-base',\n",
        "    model_kwargs={\"temperature\":0.9}\n",
        ")"
      ],
      "metadata": {
        "id": "7wt47EQzQkuk"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'Why did the chicken cross the road?'\n",
        "\n",
        "print(llm_hf(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chpL1HxRSy_N",
        "outputId": "302edce7-5cd1-4654-a7a5-2aa53b2f363d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "he was hungry\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate\n",
        "\n",
        "restaurant_template = \"\"\"\n",
        "I want you to act as a naming consultant for new restaurants.\n",
        "\n",
        "Return a list of restaurant names. Each name should be short, catchy and easy to remember. It shoud relate to the type of restaurant you are naming.\n",
        "\n",
        "What are some good names for a restaurant that is {restaurant_description}?\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables = ['restaurant_description'],\n",
        "    template = restaurant_template\n",
        ")"
      ],
      "metadata": {
        "id": "upgoWw3kTOE2"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "description = 'a Greek place that serves fresh lamb souvlakis and other Greek food'\n",
        "\n",
        "prompt.format(restaurant_description=description)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "4qY-UtK4YdFl",
        "outputId": "da6922af-7b5d-4c4d-9a1c-fd5610775bd1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nI want you to act as a naming consultant for new restaurants.\\n\\nReturn a list of restaurant names. Each name should be short, catchy and easy to remember. It shoud relate to the type of restaurant you are naming.\\n\\nWhat are some good names for a restaurant that is a Greek place that serves fresh lamb souvlakis and other Greek food?\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "\n",
        "chain = LLMChain(llm=llm_hf, prompt=prompt)\n",
        "\n",
        "print(chain.run(description))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EDmYY_EZDkB",
        "outputId": "7c7aeb2d-1d99-405b-9cbb-3d8e4473bb62"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Greek restaurant names: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate, FewShotPromptTemplate"
      ],
      "metadata": {
        "id": "T3_seX_FZ-GD"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [\n",
        "    {\"word\": \"happy\", \"antonym\": \"sad\"},\n",
        "    {\"word\": \"tall\", \"antonym\": \"short\"},\n",
        "]"
      ],
      "metadata": {
        "id": "znSd5sii8F-q"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_formatter_template = \"\"\"\n",
        "Word: {word}\n",
        "Antonym: {antonym}\\n\n",
        "\"\"\"\n",
        "\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"word\", \"antonym\"],\n",
        "    template=example_formatter_template,\n",
        ")\n",
        "\n",
        "print(example_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmZHO_Bv8nXE",
        "outputId": "b9c1303c-f413-4b9a-8d3c-9eb76ad6b8c8"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_variables=['antonym', 'word'] template='\\nWord: {word}\\nAntonym: {antonym}\\n\\n'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "few_shot_prompt = FewShotPromptTemplate(\n",
        "    examples = examples,\n",
        "    example_prompt=example_prompt,\n",
        "    prefix=\"Give the antonym of every input\",\n",
        "    suffix=\"Word: {input}\\nAntonym\",\n",
        "    input_variables=[\"input\"],\n",
        "    example_separator=\"\\n\\n\"\n",
        ")"
      ],
      "metadata": {
        "id": "mfiKbzPW9TyB"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(few_shot_prompt.format(input=\"big\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GE2CHlrv-XSx",
        "outputId": "1dcb3f2d-b4fb-4555-a986-f0995daed812"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Give the antonym of every input\n",
            "\n",
            "\n",
            "Word: happy\n",
            "Antonym: sad\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Word: tall\n",
            "Antonym: short\n",
            "\n",
            "\n",
            "\n",
            "Word: big\n",
            "Antonym\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "\n",
        "chain = LLMChain(llm=llm_hf, prompt=few_shot_prompt)\n",
        "\n",
        "print(chain.run(\"Big\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGLvQDiT-clM",
        "outputId": "8ea06a89-9b8c-4dde-a4a2-5e27306d3246"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Big\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3I8uM8Jo-9s7"
      },
      "execution_count": 34,
      "outputs": []
    }
  ]
}